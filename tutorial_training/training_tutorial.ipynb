{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist2Cell Model Training Tutorial\n",
    "\n",
    "## Welcome to the Hist2Cell Training Guide! üöÄ\n",
    "\n",
    "This comprehensive tutorial will guide you through the complete process of training a **Hist2Cell** model for predicting fine-grained cell type abundances from histology images. Whether you're new to deep learning or an experienced researcher, this guide provides step-by-step instructions with detailed explanations.\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [**Understanding Hist2Cell Training**](#understanding-hist2cell-training)\n",
    "2. [**Environment Setup & Reproducibility**](#environment-setup--reproducibility)\n",
    "3. [**Model Architecture Deep Dive**](#model-architecture-deep-dive)\n",
    "4. [**Data Loading & Preparation**](#data-loading--preparation)\n",
    "5. [**Training Configuration**](#training-configuration)\n",
    "6. [**Training Process & Monitoring**](#training-process--monitoring)\n",
    "7. [**Results Analysis & Next Steps**](#results-analysis--next-steps)\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- ‚úÖ Understand the complete Hist2Cell training pipeline\n",
    "- ‚úÖ Master multi-scale graph neural network training\n",
    "- ‚úÖ Learn advanced spatial transcriptomics modeling techniques\n",
    "- ‚úÖ Implement robust model evaluation and validation\n",
    "- ‚úÖ Optimize training for your own datasets\n",
    "\n",
    "## üß¨ Understanding Hist2Cell Training\n",
    "\n",
    "**Hist2Cell** represents a paradigm shift in spatial biology analysis by directly predicting cell type abundances from histology images without requiring explicit gene expression measurements at inference time.\n",
    "\n",
    "### üî¨ **The Challenge**\n",
    "Traditional spatial transcriptomics analysis requires:\n",
    "- **Expensive sequencing**: Costly gene expression measurements\n",
    "- **Limited resolution**: Constrained by sequencing spot size\n",
    "- **Processing time**: Long sequencing and analysis pipelines\n",
    "\n",
    "### üéØ **The Hist2Cell Solution**\n",
    "Our approach enables:\n",
    "- **Cost-effective prediction**: Uses only histology images\n",
    "- **High resolution**: Patch-level predictions at any scale\n",
    "- **Fast inference**: Real-time analysis of tissue slides\n",
    "- **Broad applicability**: Works across different tissue types\n",
    "\n",
    "### üèóÔ∏è **Model Innovation**\n",
    "Hist2Cell combines three powerful approaches:\n",
    "1. **Local Feature Extractor**: ResNet18 extracts visual features from tissue patches\n",
    "2. **Graph Neural Networks**: Model spatial relationships between tissue regions\n",
    "3. **Vision Transformers**: Capture global tissue context and patterns\n",
    "\n",
    "## üìä **Training Strategy**\n",
    "\n",
    "### üéØ **Multi-scale Learning**\n",
    "- **Spot-level**: Individual patch analysis\n",
    "- **Local-level**: Neighborhood pattern recognition\n",
    "- **Global-level**: Tissue-wide context understanding\n",
    "- **Fusion-level**: Integrated multi-scale predictions\n",
    "\n",
    "### üìà **Evaluation Strategy**\n",
    "- **Donor-based splits**: Test generalization across individuals\n",
    "- **Multi-metric evaluation**: Loss, correlation, and biological validation\n",
    "- **Real-time monitoring**: Track training progress and convergence\n",
    "\n",
    "## üîß **Prerequisites**\n",
    "\n",
    "Before starting, ensure you have:\n",
    "- **Processed data**: From the data preparation tutorial\n",
    "- **GPU access**: 8GB+ VRAM recommended (24GB+ ideal)\n",
    "- **Python environment**: With PyTorch, PyTorch Geometric, and dependencies\n",
    "\n",
    "## 1. Environment Setup & Reproducibility\n",
    "\n",
    "### üé≤ **Why Reproducibility Matters**\n",
    "\n",
    "In machine learning research, **reproducibility** is crucial for:\n",
    "- **Scientific validity**: Others can verify your results\n",
    "- **Debugging**: Consistent behavior across runs\n",
    "- **Comparison**: Fair evaluation of different approaches\n",
    "- **Production deployment**: Predictable model behavior\n",
    "\n",
    "### üîß **Random Seed Management**\n",
    "\n",
    "We'll set random seeds for all major libraries to ensure deterministic behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Random seed setup completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "def setup_seed(seed):\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across different libraries and frameworks.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): The random seed value to use\n",
    "    \n",
    "    Note:\n",
    "        This function ensures that:\n",
    "        - All random number generators use the same seed\n",
    "        - Results are reproducible across different runs\n",
    "        - Both CPU and GPU computations are deterministic\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)                    # Set PyTorch random seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)   # Set Python hash seed\n",
    "    torch.cuda.manual_seed(seed)               # Set CUDA random seed for current GPU\n",
    "    torch.cuda.manual_seed_all(seed)           # Set CUDA random seed for all GPUs\n",
    "    np.random.seed(seed)                       # Set NumPy random seed\n",
    "    random.seed(seed)                          # Set Python random seed\n",
    "    torch.backends.cudnn.benchmark = False    # Disable cuDNN benchmark for reproducibility\n",
    "    torch.backends.cudnn.deterministic = True # Use deterministic algorithms\n",
    "    torch.backends.cudnn.enabled = True       # Enable cuDNN\n",
    "\n",
    "# Set random seed to 3407 (a commonly used seed value in ML research)\n",
    "setup_seed(3407)\n",
    "print(\"‚úì Random seed setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Device Configuration & GPU Setup\n",
    "\n",
    "### üéØ **Why GPU Training Matters**\n",
    "\n",
    "Training Hist2Cell involves processing:\n",
    "- **Large image tensors**: 224√ó224√ó3 patches for hundreds of spots\n",
    "- **Complex graph operations**: Spatial relationships between neighboring regions\n",
    "- **Transformer computations**: Self-attention mechanisms across tissue contexts\n",
    "- **Multi-scale processing**: Simultaneous spot, local, and global analysis\n",
    "\n",
    "**GPU acceleration** provides:\n",
    "- **10-50x speedup**: Compared to CPU training\n",
    "- **Parallel processing**: Handle multiple spots simultaneously\n",
    "- **Memory efficiency**: Large VRAM for batch processing\n",
    "- **Optimized operations**: Specialized CUDA kernels for deep learning\n",
    "\n",
    "### üîß **GPU Requirements**\n",
    "\n",
    "| GPU Memory | Recommended Batch Size | Training Time (5 epochs) |\n",
    "|------------|------------------------|---------------------------|\n",
    "| **8GB** | `subgraph_bs=4` | ~60 minutes |\n",
    "| **12GB** | `subgraph_bs=8` | ~45 minutes |\n",
    "| **16GB** | `subgraph_bs=12` | ~35 minutes |\n",
    "| **24GB+** | `subgraph_bs=16` | ~30 minutes |\n",
    "\n",
    "### ‚ö° **Device Detection & Configuration**\n",
    "\n",
    "Let's configure the optimal computing device for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3090\n",
      "GPU Memory: 23.7 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Suppress warning messages for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure GPU settings\n",
    "gpu_list = [0]  # Use GPU 0 (first GPU). Change this if you want to use different GPUs\n",
    "gpu_list_str = ','.join(map(str, gpu_list))\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", gpu_list_str)\n",
    "\n",
    "# Set device for training (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Display device information\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Warning: CUDA not available. Training will be slower on CPU.\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "### Understanding the Hist2Cell Architecture\n",
    "\n",
    "The Hist2Cell model is a sophisticated neural network that combines multiple components:\n",
    "\n",
    "1. **ResNet18 Backbone**: Extracts 512-dimensional features from histology image patches\n",
    "2. **Graph Attention Network (GAT)**: Captures spatial relationships between neighboring spots\n",
    "3. **Vision Transformer (ViT)**: Processes global context across the entire tissue slide\n",
    "4. **Multi-level Prediction Fusion**: Combines spot-level, local, global, and fused predictions\n",
    "\n",
    "**Key Innovation**: Unlike single-scale approaches, Hist2Cell leverages information at multiple spatial scales to achieve more accurate cell type abundance predictions.\n",
    "\n",
    "Let's define the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hist2Cell model...\n",
      "‚úì Model initialized successfully!\n",
      "Total parameters: 14,232,064\n",
      "Trainable parameters: 14,232,064\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules for model definition\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "import sys, os\n",
    "\n",
    "# Add parent directory to path to import custom modules\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from model.ViT import Mlp, VisionTransformer\n",
    "\n",
    "class Hist2Cell(nn.Module):\n",
    "    \"\"\"\n",
    "    Hist2Cell model for predicting cell type abundances from histology images.\n",
    "    \n",
    "    This model combines multiple approaches:\n",
    "    1. ResNet18 for image feature extraction\n",
    "    2. Graph Attention Network for spatial relationship modeling\n",
    "    3. Vision Transformer for global context understanding\n",
    "    4. Multi-level prediction fusion\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cell_dim=80, vit_depth=3):\n",
    "        \"\"\"\n",
    "        Initialize the Hist2Cell model.\n",
    "        \n",
    "        Args:\n",
    "            cell_dim (int): Number of cell types to predict (default: 80)\n",
    "            vit_depth (int): Depth of Vision Transformer (default: 3)\n",
    "        \"\"\"\n",
    "        super(Hist2Cell, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet18 and remove the final classification layer\n",
    "        self.resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.resnet18 = torch.nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "        \n",
    "        # Model hyperparameters\n",
    "        self.embed_dim = 32 * 8  # Embedding dimension (256)\n",
    "        self.head = 8            # Number of attention heads\n",
    "        self.dropout = 0.3       # Dropout rate\n",
    "        \n",
    "        # Graph Attention Network for local spatial relationships\n",
    "        self.conv1 = GATv2Conv(\n",
    "            in_channels=512,  # ResNet18 output features\n",
    "            out_channels=int(self.embed_dim/self.head),  # 32 features per head\n",
    "            heads=self.head   # 8 attention heads\n",
    "        )\n",
    "        self.norm1 = LayerNorm(in_channels=self.embed_dim)\n",
    "        \n",
    "        # Vision Transformer for global context\n",
    "        self.cell_transformer = VisionTransformer(\n",
    "            num_classes=cell_dim,\n",
    "            embed_dim=self.embed_dim,\n",
    "            depth=vit_depth,\n",
    "            mlp_head=True,\n",
    "            drop_rate=self.dropout,\n",
    "            attn_drop_rate=self.dropout\n",
    "        )\n",
    "        \n",
    "        # Prediction heads for different levels\n",
    "        self.spot_fc = Linear(in_features=512, out_features=256)\n",
    "        self.spot_head = Mlp(in_features=256, hidden_features=512*2, out_features=cell_dim)\n",
    "        self.local_head = Mlp(in_features=256, hidden_features=512*2, out_features=cell_dim)\n",
    "        self.fused_head = Mlp(in_features=256, hidden_features=512*2, out_features=cell_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Forward pass of the Hist2Cell model.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input histology images\n",
    "            edge_index (torch.Tensor): Graph edge indices for spatial relationships\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Predicted cell type abundances\n",
    "        \"\"\"\n",
    "        # Extract features using ResNet18\n",
    "        x_spot = self.resnet18(x)\n",
    "        x_spot = x_spot.squeeze()\n",
    "        \n",
    "        # Process with Graph Attention Network\n",
    "        x_local = self.conv1(x=x_spot, edge_index=edge_index)\n",
    "        x_local = self.norm1(x_local)\n",
    "        \n",
    "        # Prepare for Vision Transformer\n",
    "        x_local = x_local.unsqueeze(0)\n",
    "        x_cell = x_local\n",
    "        \n",
    "        # Generate predictions at different levels\n",
    "        # 1. Spot-level prediction\n",
    "        x_spot = self.spot_fc(x_spot)\n",
    "        cell_predication_spot = self.spot_head(x_spot)\n",
    "        \n",
    "        # 2. Local-level prediction (GAT output)\n",
    "        x_local = x_local.squeeze(0)\n",
    "        cell_prediction_local = self.local_head(x_local)\n",
    "        \n",
    "        # 3. Global-level prediction (Vision Transformer)\n",
    "        cell_prediction_global, x_global = self.cell_transformer(x_cell)\n",
    "        cell_prediction_global = cell_prediction_global.squeeze()\n",
    "        x_global = x_global.squeeze()\n",
    "        \n",
    "        # 4. Fused prediction (average of all feature representations)\n",
    "        cell_prediction_fused = self.fused_head((x_spot + x_local + x_global) / 3.0)\n",
    "        \n",
    "        # Final prediction: average of all four prediction levels\n",
    "        cell_prediction = (cell_predication_spot + cell_prediction_local + \n",
    "                          cell_prediction_global + cell_prediction_fused) / 4.0\n",
    "        \n",
    "        # Apply ReLU activation to ensure non-negative cell abundances\n",
    "        cell_prediction = torch.relu(cell_prediction)\n",
    "        \n",
    "        return cell_prediction\n",
    "\n",
    "# Initialize the model\n",
    "print(\"Initializing Hist2Cell model...\")\n",
    "model = Hist2Cell(vit_depth=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"‚úì Model initialized successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "### Understanding the Dataset Split\n",
    "\n",
    "We use a **donor-based split** strategy for our training and testing:\n",
    "\n",
    "- **Training**: 3 donors (9 slides total) - Donors A37, A32, A28\n",
    "- **Testing**: 1 donor (2 slides total) - Donor A50\n",
    "\n",
    "This approach ensures that the model is tested on completely unseen donor data, which is crucial for evaluating generalization capability across different individuals and biological conditions.\n",
    "\n",
    "#### Dataset Overview:\n",
    "\n",
    "**Test slides (Donor A50):**\n",
    "- WSA_LngSP9258463\n",
    "- WSA_LngSP9258467\n",
    "\n",
    "**Training slides (Other 3 donors):**\n",
    "- WSA_LngSP8759311\n",
    "- WSA_LngSP8759312\n",
    "- WSA_LngSP8759313\n",
    "- WSA_LngSP9258464\n",
    "- WSA_LngSP9258468\n",
    "- WSA_LngSP10193347\n",
    "- WSA_LngSP10193348\n",
    "- WSA_LngSP10193345\n",
    "- WSA_LngSP10193346\n",
    "\n",
    "### Loading Train/Test Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/test split files...\n",
      "Training slides: 9 slides\n",
      "Testing slides: 2 slides\n",
      "\n",
      "Training slides: ['WSA_LngSP8759311', 'WSA_LngSP8759312', 'WSA_LngSP8759313', 'WSA_LngSP9258464', 'WSA_LngSP9258468', 'WSA_LngSP10193347', 'WSA_LngSP10193348', 'WSA_LngSP10193345', 'WSA_LngSP10193346']\n",
      "Testing slides: ['WSA_LngSP9258463', 'WSA_LngSP9258467']\n",
      "‚úì Split files loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load train/test split files\n",
    "print(\"Loading train/test split files...\")\n",
    "\n",
    "# Read training slide names (leave-one-donor-out strategy)\n",
    "train_slides = open(\"../train_test_splits/humanlung_cell2location/train_leave_A50.txt\").read().split('\\n')\n",
    "\n",
    "# Read testing slide names (donor A50 only)\n",
    "test_slides = open(\"../train_test_splits/humanlung_cell2location/test_leave_A50.txt\").read().split('\\n')\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Training slides: {len(train_slides)} slides\")\n",
    "print(f\"Testing slides: {len(test_slides)} slides\")\n",
    "print(f\"\\nTraining slides: {train_slides}\")\n",
    "print(f\"Testing slides: {test_slides}\")\n",
    "print(\"‚úì Split files loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Processed Graph Data\n",
    "\n",
    "Each slide has been preprocessed into a graph structure where:\n",
    "- **Nodes**: Represent spatial spots with histology image patches\n",
    "- **Edges**: Connect neighboring spots based on spatial proximity\n",
    "- **Node Features**: Include both image features and spatial coordinates\n",
    "- **Labels**: Cell type abundance values for each spot\n",
    "\n",
    "The data is stored in PyTorch Geometric format (`.pt` files) for efficient loading and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed graph data...\n",
      "Loading training graphs:\n",
      "  - WSA_LngSP8759311: 2251 nodes, 15033 edges\n",
      "  - WSA_LngSP8759312: 2564 nodes, 17216 edges\n",
      "  - WSA_LngSP8759313: 2001 nodes, 13477 edges\n",
      "  - WSA_LngSP9258464: 2323 nodes, 15413 edges\n",
      "  - WSA_LngSP9258468: 2285 nodes, 14999 edges\n",
      "  - WSA_LngSP10193347: 1937 nodes, 12171 edges\n",
      "  - WSA_LngSP10193348: 937 nodes, 5903 edges\n",
      "  - WSA_LngSP10193345: 3234 nodes, 21332 edges\n",
      "  - WSA_LngSP10193346: 2430 nodes, 16300 edges\n",
      "\n",
      "Loading testing graphs:\n",
      "  - WSA_LngSP9258463: 386 nodes, 2442 edges\n",
      "  - WSA_LngSP9258467: 422 nodes, 2732 edges\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "Training dataset:\n",
      "  - Total nodes: 19962\n",
      "  - Total edges: 131844\n",
      "  - Node features: torch.Size([19962, 3, 224, 224])\n",
      "  - Labels: torch.Size([19962, 330])\n",
      "\n",
      "Testing dataset:\n",
      "  - Total nodes: 808\n",
      "  - Total edges: 5174\n",
      "  - Node features: torch.Size([808, 3, 224, 224])\n",
      "  - Labels: torch.Size([808, 330])\n",
      "‚úì Graph data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch Geometric utilities\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "print(\"Loading processed graph data...\")\n",
    "\n",
    "# Load training data\n",
    "train_graph_list = []\n",
    "print(\"Loading training graphs:\")\n",
    "for item in train_slides:\n",
    "    if item:  # Skip empty strings\n",
    "        graph_path = os.path.join(\"../example_data/humanlung_cell2location\", item + '.pt')\n",
    "        graph = torch.load(graph_path)\n",
    "        train_graph_list.append(graph)\n",
    "        print(f\"  - {item}: {graph.num_nodes} nodes, {graph.num_edges} edges\")\n",
    "\n",
    "# Combine all training graphs into a single batch\n",
    "train_dataset = Batch.from_data_list(train_graph_list)\n",
    "\n",
    "# Load testing data\n",
    "test_graph_list = []\n",
    "print(\"\\nLoading testing graphs:\")\n",
    "for item in test_slides:\n",
    "    if item:  # Skip empty strings\n",
    "        graph_path = os.path.join(\"../example_data/humanlung_cell2location\", item + '.pt')\n",
    "        graph = torch.load(graph_path)\n",
    "        test_graph_list.append(graph)\n",
    "        print(f\"  - {item}: {graph.num_nodes} nodes, {graph.num_edges} edges\")\n",
    "\n",
    "# Combine all testing graphs into a single batch\n",
    "test_dataset = Batch.from_data_list(test_graph_list)\n",
    "\n",
    "# Display dataset statistics\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"Training dataset:\")\n",
    "print(f\"  - Total nodes: {train_dataset.num_nodes}\")\n",
    "print(f\"  - Total edges: {train_dataset.num_edges}\")\n",
    "print(f\"  - Node features: {train_dataset.x.shape}\")\n",
    "print(f\"  - Labels: {train_dataset.y.shape}\")\n",
    "\n",
    "print(f\"\\nTesting dataset:\")\n",
    "print(f\"  - Total nodes: {test_dataset.num_nodes}\")\n",
    "print(f\"  - Total edges: {test_dataset.num_edges}\")\n",
    "print(f\"  - Node features: {test_dataset.x.shape}\")\n",
    "print(f\"  - Labels: {test_dataset.y.shape}\")\n",
    "\n",
    "print(\"‚úì Graph data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader Configuration\n",
    "\n",
    "For efficient training on large graphs, we use **subgraph sampling** with `NeighborLoader`. This approach:\n",
    "- Samples subgraphs around center nodes\n",
    "- Reduces memory usage by processing smaller graph portions\n",
    "- Maintains spatial context through neighborhood sampling\n",
    "\n",
    "#### Key Parameters:\n",
    "\n",
    "- **`hop`**: Defines the receptive field (neighborhood size)\n",
    "  - `hop=2` means we include 2-hop neighbors around each center node\n",
    "  - Larger hop ‚Üí more context but higher memory usage\n",
    "  - We use 2-hop for optimal balance between performance and efficiency\n",
    "\n",
    "- **`subgraph_bs`**: Subgraph batch size\n",
    "  - Number of center nodes processed simultaneously\n",
    "  - `subgraph_bs=16` works well on RTX 3090 GPU (24GB memory)\n",
    "  - For smaller GPUs: try `subgraph_bs=8` (12GB) or `subgraph_bs=4` (8GB)\n",
    "  - Larger values improve training efficiency but require more memory\n",
    "\n",
    "- **`num_neighbors`**: Number of neighbors to sample at each hop\n",
    "  - `[-1]` means sample all neighbors (no sampling)\n",
    "  - Can use smaller values like `[10, 5]` for very large graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch_geometric\n",
    "\n",
    "# Disable PyG lib for compatibility\n",
    "torch_geometric.typing.WITH_PYG_LIB = False\n",
    "\n",
    "print(\"Configuring DataLoaders...\")\n",
    "\n",
    "# DataLoader parameters\n",
    "hop = 2              # 2-hop neighborhood sampling\n",
    "subgraph_bs = 16     # Subgraph batch size (adjust based on GPU memory)\n",
    "\n",
    "print(f\"Parameters:\")\n",
    "print(f\"  - Hop distance: {hop}\")\n",
    "print(f\"  - Subgraph batch size: {subgraph_bs}\")\n",
    "print(f\"  - Neighbor sampling: all neighbors ([-1] * {hop})\")\n",
    "\n",
    "# Create training data loader\n",
    "train_loader = NeighborLoader(\n",
    "    train_dataset,\n",
    "    num_neighbors=[-1] * hop,    # Sample all neighbors at each hop\n",
    "    batch_size=subgraph_bs,      # Number of center nodes per batch\n",
    "    directed=False,              # Undirected graph\n",
    "    input_nodes=None,            # Use all nodes as potential centers\n",
    "    shuffle=True,                # Shuffle for training\n",
    "    num_workers=2,               # Parallel data loading\n",
    ")\n",
    "\n",
    "# Create testing data loader\n",
    "test_loader = NeighborLoader(\n",
    "    test_dataset,\n",
    "    num_neighbors=[-1] * hop,    # Sample all neighbors at each hop\n",
    "    batch_size=subgraph_bs,      # Number of center nodes per batch\n",
    "    directed=False,              # Undirected graph\n",
    "    input_nodes=None,            # Use all nodes as potential centers\n",
    "    shuffle=False,               # No shuffling for testing\n",
    "    num_workers=2,               # Parallel data loading\n",
    ")\n",
    "\n",
    "# Display loader information\n",
    "print(f\"\\nüìã DataLoader Information:\")\n",
    "print(f\"Training loader:\")\n",
    "print(f\"  - Approximate batches per epoch: {len(train_loader)}\")\n",
    "print(f\"  - Shuffling: {train_loader.shuffle}\")\n",
    "\n",
    "print(f\"\\nTesting loader:\")\n",
    "print(f\"  - Approximate batches per epoch: {len(test_loader)}\")\n",
    "print(f\"  - Shuffling: {test_loader.shuffle}\")\n",
    "\n",
    "print(\"‚úì DataLoaders configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "### Setting Up Training Components\n",
    "\n",
    "Before we start training, we need to configure several key components:\n",
    "\n",
    "#### üéØ Loss Function\n",
    "- **MSE Loss**: Mean Squared Error for regression (predicting continuous cell abundance values)\n",
    "\n",
    "#### üöÄ Optimizer\n",
    "- **Adam**: Adaptive learning rate optimizer\n",
    "- **Learning Rate**: `1e-4` (0.0001) - a good starting point for most deep learning tasks\n",
    "- **Weight Decay**: `1e-4` for regularization to prevent overfitting\n",
    "\n",
    "#### üìà Learning Rate Scheduler\n",
    "- **CosineAnnealingLR**: Gradually decreases learning rate following a cosine curve\n",
    "- **T_max**: 20 epochs for the annealing schedule\n",
    "- **eta_min**: Minimum learning rate of `1e-5`\n",
    "\n",
    "These settings have been empirically validated and work well for the Hist2Cell model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "print(\"Setting up training configuration...\")\n",
    "\n",
    "# Learning rate\n",
    "lr = 1e-4\n",
    "print(f\"Learning rate: {lr}\")\n",
    "\n",
    "# Get model parameters\n",
    "params = model.parameters()\n",
    "\n",
    "# Define loss function (Mean Squared Error for regression)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "print(f\"Loss function: MSE Loss\")\n",
    "\n",
    "# Define optimizer (Adam with weight decay for regularization)\n",
    "optimizer = torch.optim.Adam(\n",
    "    params, \n",
    "    lr=lr, \n",
    "    weight_decay=1e-4  # L2 regularization\n",
    ")\n",
    "print(f\"Optimizer: Adam (lr={lr}, weight_decay=1e-4)\")\n",
    "\n",
    "# Define learning rate scheduler (Cosine Annealing)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=20,           # Maximum number of epochs for annealing\n",
    "    eta_min=1e-5,       # Minimum learning rate\n",
    "    last_epoch=-1,      # Start from the beginning\n",
    "    verbose=False       # Don't print lr updates\n",
    ")\n",
    "print(f\"Scheduler: CosineAnnealingLR (T_max=20, eta_min=1e-5)\")\n",
    "\n",
    "print(\"‚úì Training configuration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "Now we're ready to start training! This section will:\n",
    "\n",
    "1. **Train the model** for multiple epochs\n",
    "2. **Monitor performance** on both training and test sets\n",
    "3. **Save the best model** based on test performance\n",
    "4. **Track metrics** including loss and Pearson correlation\n",
    "\n",
    "#### Key Metrics:\n",
    "- **Loss**: MSE loss for training optimization\n",
    "- **Pearson R**: Correlation coefficient measuring prediction quality\n",
    "- **Best model**: Saved based on highest test Pearson R\n",
    "\n",
    "#### Training Process:\n",
    "- **Epochs**: 5 (for demonstration - increase to 20-50 for production)\n",
    "- **Evaluation**: After each epoch on both training and test sets\n",
    "- **Model Saving**: Only when test Pearson R improves (best model checkpoint)\n",
    "- **Progress Tracking**: Real-time loss and correlation monitoring\n",
    "\n",
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch: 1 \t\n",
      "lr =  9.94459753267812e-05\n",
      "saving best cell all abundance average 0.25637321132934027\n",
      "Training complete in 6m 35s\n",
      "Epoch: 1 \tTraining Cell abundance Loss: 0.083641\n",
      "Epoch: 1 \tTraining Cell abundance pearson all average: 0.807833\n",
      "Epoch: 1 \tTest Cell abundance Loss: 0.474147\n",
      "Epoch: 1 \tTest Cell abundance pearson all average: 0.256373\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch: 2 \t\n",
      "lr =  9.779754323328192e-05\n",
      "Training complete in 13m 9s\n",
      "Epoch: 2 \tTraining Cell abundance Loss: 0.055636\n",
      "Epoch: 2 \tTraining Cell abundance pearson all average: 0.841353\n",
      "Epoch: 2 \tTest Cell abundance Loss: 0.492704\n",
      "Epoch: 2 \tTest Cell abundance pearson all average: 0.255606\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch: 3 \t\n",
      "lr =  9.509529358847657e-05\n",
      "saving best cell all abundance average 0.27884169006691606\n",
      "Training complete in 19m 42s\n",
      "Epoch: 3 \tTraining Cell abundance Loss: 0.043690\n",
      "Epoch: 3 \tTraining Cell abundance pearson all average: 0.863058\n",
      "Epoch: 3 \tTest Cell abundance Loss: 0.517205\n",
      "Epoch: 3 \tTest Cell abundance pearson all average: 0.278842\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch: 4 \t\n",
      "lr =  9.140576474687265e-05\n",
      "Training complete in 26m 14s\n",
      "Epoch: 4 \tTraining Cell abundance Loss: 0.035573\n",
      "Epoch: 4 \tTraining Cell abundance pearson all average: 0.880660\n",
      "Epoch: 4 \tTest Cell abundance Loss: 0.497146\n",
      "Epoch: 4 \tTest Cell abundance pearson all average: 0.264278\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch: 5 \t\n",
      "lr =  8.681980515339465e-05\n",
      "saving best cell all abundance average 0.2906273744244606\n",
      "Training complete in 32m 46s\n",
      "Epoch: 5 \tTraining Cell abundance Loss: 0.030300\n",
      "Epoch: 5 \tTraining Cell abundance pearson all average: 0.889585\n",
      "Epoch: 5 \tTest Cell abundance Loss: 0.440500\n",
      "Epoch: 5 \tTest Cell abundance pearson all average: 0.290627\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for training\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 5\n",
    "print(f\"üöÄ Starting training for {num_epochs} epochs...\\n\")\n",
    "\n",
    "# Initialize tracking variables\n",
    "best_cell_abundance_all_average = 0.0\n",
    "since = time.time()\n",
    "\n",
    "# Create directory for saving model weights\n",
    "os.makedirs(\"../model_weights\", exist_ok=True)\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"=\" * 100)\n",
    "    print(f'üìÖ Epoch: {epoch + 1}/{num_epochs}')\n",
    "    print(f'üìä Current learning rate: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "    \n",
    "    # =============================================================================\n",
    "    # TRAINING PHASE\n",
    "    # =============================================================================\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    # Initialize training metrics\n",
    "    train_sample_num = 0\n",
    "    train_cell_pred_array = []\n",
    "    train_cell_label_array = []\n",
    "    train_cell_abundance_loss = 0\n",
    "    \n",
    "    print(\"üèãÔ∏è Training...\")\n",
    "    for batch_idx, graph in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        x = graph.x.to(device)\n",
    "        y = graph.y.to(device)\n",
    "        edge_index = graph.edge_index.to(device)\n",
    "        \n",
    "        # Extract cell abundance labels (columns 250 onwards)\n",
    "        cell_label = y[:, 250:]\n",
    "        \n",
    "        # Forward pass\n",
    "        cell_pred = model(x=x, edge_index=edge_index)\n",
    "        \n",
    "        # Calculate loss\n",
    "        cell_loss = criterion(cell_pred, cell_label)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        cell_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Collect predictions and labels for evaluation\n",
    "        center_num = len(graph.input_id)  # Number of center nodes\n",
    "        center_cell_label = cell_label[:center_num, :]\n",
    "        center_cell_pred = cell_pred[:center_num, :]\n",
    "        \n",
    "        # Store predictions and labels\n",
    "        train_cell_label_array.append(center_cell_label.squeeze().cpu().detach().numpy())\n",
    "        train_cell_pred_array.append(center_cell_pred.squeeze().cpu().detach().numpy())\n",
    "        train_sample_num += center_num\n",
    "        train_cell_abundance_loss += cell_loss.item() * center_num\n",
    "        \n",
    "        # Print progress\n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_loader)}, Loss: {cell_loss.item():.6f}\")\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    train_cell_abundance_loss = train_cell_abundance_loss / train_sample_num\n",
    "    \n",
    "    # Prepare arrays for correlation calculation\n",
    "    if len(train_cell_pred_array[-1].shape) == 1:\n",
    "        train_cell_pred_array[-1] = np.expand_dims(train_cell_pred_array[-1], axis=0)\n",
    "    train_cell_pred_array = np.concatenate(train_cell_pred_array)\n",
    "    \n",
    "    if len(train_cell_label_array[-1].shape) == 1:\n",
    "        train_cell_label_array[-1] = np.expand_dims(train_cell_label_array[-1], axis=0)\n",
    "    train_cell_label_array = np.concatenate(train_cell_label_array)\n",
    "    \n",
    "    # Calculate average Pearson correlation across all cell types\n",
    "    train_cell_abundance_all_pearson_average = 0.0\n",
    "    for i in range(train_cell_pred_array.shape[1]):\n",
    "        r, p = pearsonr(train_cell_pred_array[:, i], train_cell_label_array[:, i])\n",
    "        train_cell_abundance_all_pearson_average += r\n",
    "    train_cell_abundance_all_pearson_average /= train_cell_pred_array.shape[1]\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # =============================================================================\n",
    "    # EVALUATION PHASE\n",
    "    # =============================================================================\n",
    "    print(\"üß™ Evaluating...\")\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        # Initialize evaluation metrics\n",
    "        test_sample_num = 0\n",
    "        test_cell_pred_array = []\n",
    "        test_cell_label_array = []\n",
    "        test_cell_abundance_loss = 0\n",
    "        \n",
    "        for graph in test_loader:\n",
    "            # Move data to device\n",
    "            x = graph.x.to(device)\n",
    "            y = graph.y.to(device)\n",
    "            edge_index = graph.edge_index.to(device)\n",
    "            \n",
    "            # Extract cell abundance labels\n",
    "            cell_label = y[:, 250:]\n",
    "            \n",
    "            # Forward pass (no gradients needed)\n",
    "            cell_pred = model(x=x, edge_index=edge_index)\n",
    "            \n",
    "            # Calculate loss\n",
    "            cell_loss = criterion(cell_pred, cell_label)\n",
    "            \n",
    "            # Collect predictions and labels\n",
    "            center_num = len(graph.input_id)\n",
    "            center_cell_label = cell_label[:center_num, :]\n",
    "            center_cell_pred = cell_pred[:center_num, :]\n",
    "            \n",
    "            test_cell_label_array.append(center_cell_label.squeeze().cpu().detach().numpy())\n",
    "            test_cell_pred_array.append(center_cell_pred.squeeze().cpu().detach().numpy())\n",
    "            test_sample_num += center_num\n",
    "            test_cell_abundance_loss += cell_loss.item() * center_num\n",
    "        \n",
    "        # Calculate average test loss\n",
    "        test_cell_abundance_loss = test_cell_abundance_loss / test_sample_num\n",
    "    \n",
    "    # Prepare arrays for correlation calculation\n",
    "    if len(test_cell_pred_array[-1].shape) == 1:\n",
    "        test_cell_pred_array[-1] = np.expand_dims(test_cell_pred_array[-1], axis=0)\n",
    "    test_cell_pred_array = np.concatenate(test_cell_pred_array)\n",
    "    \n",
    "    if len(test_cell_label_array[-1].shape) == 1:\n",
    "        test_cell_label_array[-1] = np.expand_dims(test_cell_label_array[-1], axis=0)\n",
    "    test_cell_label_array = np.concatenate(test_cell_label_array)\n",
    "    \n",
    "    # Calculate average Pearson correlation across all cell types\n",
    "    test_cell_abundance_all_pearson_average = 0.0\n",
    "    for i in range(test_cell_pred_array.shape[1]):\n",
    "        r, p = pearsonr(test_cell_pred_array[:, i], test_cell_label_array[:, i])\n",
    "        test_cell_abundance_all_pearson_average += r\n",
    "    test_cell_abundance_all_pearson_average /= test_cell_pred_array.shape[1]\n",
    "    \n",
    "    # =============================================================================\n",
    "    # MODEL SAVING AND LOGGING\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Save model if test performance improved\n",
    "    if test_cell_abundance_all_pearson_average > best_cell_abundance_all_average:\n",
    "        best_cell_abundance_all_average = test_cell_abundance_all_pearson_average\n",
    "        torch.save(model.state_dict(), os.path.join(\"../model_weights\", \"demo_ckpt.pth\"))\n",
    "        print(f\"üíæ New best model saved! Test Pearson R: {test_cell_abundance_all_pearson_average:.6f}\")\n",
    "    \n",
    "    # Calculate and display timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'‚è±Ô∏è Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
    "    \n",
    "    # Display epoch results\n",
    "    print(f'\\nüìà Epoch {epoch + 1} Results:')\n",
    "    print(f'  Training Loss: {train_cell_abundance_loss:.6f}')\n",
    "    print(f'  Training Pearson R: {train_cell_abundance_all_pearson_average:.6f}')\n",
    "    print(f'  Test Loss: {test_cell_abundance_loss:.6f}')\n",
    "    print(f'  Test Pearson R: {test_cell_abundance_all_pearson_average:.6f}')\n",
    "    print(f'  Best Test Pearson R: {best_cell_abundance_all_average:.6f}')\n",
    "    print()\n",
    "\n",
    "print(\"üéâ Training completed successfully!\")\n",
    "print(f\"üèÜ Best test Pearson R achieved: {best_cell_abundance_all_average:.6f}\")\n",
    "print(f\"üíæ Best model saved to: ../model_weights/demo_ckpt.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Tutorial Complete! üéâ\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Congratulations! You've successfully completed the Hist2Cell training tutorial. Here's what you've learned:\n",
    "\n",
    "‚úÖ **Environment Setup**: Configured random seeds and GPU settings for reproducible training  \n",
    "‚úÖ **Model Architecture**: Understood the multi-component Hist2Cell model structure  \n",
    "‚úÖ **Data Loading**: Loaded and prepared graph-structured histology data  \n",
    "‚úÖ **Training Configuration**: Set up loss functions, optimizers, and learning rate schedulers  \n",
    "‚úÖ **Training Loop**: Implemented a complete training pipeline with evaluation and model saving  \n",
    "\n",
    "### Key Results\n",
    "\n",
    "- **Model**: Successfully trained Hist2Cell for cell type abundance prediction\n",
    "- **Saved Model**: Best checkpoint saved to `../model_weights/demo_ckpt.pth`\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Now that you've trained your model, explore these additional tutorials to maximize your analysis:\n",
    "\n",
    "#### 1. **Data Preparation**\n",
    "- `../tutorial_data_preparation/data_preparation_tutorial.ipynb`\n",
    "- Learn how to preprocess your own histology data for Hist2Cell training\n",
    "- Understand the data structure and format requirements\n",
    "\n",
    "#### 2. **Analysis and Evaluation**\n",
    "Explore the comprehensive analysis tutorials in `../tutorial_analysis_evaluation/`:\n",
    "\n",
    "- **`cell_abundance_visulization_tutorial.ipynb`**: Visualize predicted cell abundances for biological discovery\n",
    "- **`key_cell_evaluation_tutorial.ipynb`**: Evaluate model performance on specific cell types of interest  \n",
    "- **`cell_colocalization_tutorial.ipynb`**: Analyze spatial cell co-localization patterns\n",
    "- **`super_resovled_cell_abundance_tutorial.ipynb`**: Generate super-resolved cell abundance maps\n",
    "\n",
    "#### 3. **Model Improvements**\n",
    "- **More Epochs**: Train for 20-50 epochs for better convergence (this demo used only 5 for quick demonstration)\n",
    "- **Hyperparameter Tuning**: \n",
    "  - Learning rates: Try `5e-5`, `1e-4` (current), `2e-4`, `5e-4`\n",
    "  - Subgraph batch sizes: Adjust `8`, `16` (current), `32` based on GPU memory\n",
    "  - ViT depths: Experiment with `2`, `3` (current), `4`, `5` layers\n",
    "  - Model dimensions: Try `cell_dim=80` (current) or adjust for your dataset\n",
    "- **Custom Datasets**: Apply the data preparation pipeline to your own histology data\n",
    "\n",
    "#### 4. **Advanced Usage**\n",
    "- **Fine-tuning**: Adapt pre-trained models to new datasets\n",
    "- **Integration**: Incorporate Hist2Cell into your spatial biology analysis pipeline\n",
    "- **Batch Processing**: Process multiple slides efficiently\n",
    "\n",
    "### Available Resources\n",
    "\n",
    "This project provides:\n",
    "- **Pre-trained Models**: Check `../model_weights/` for trained checkpoints\n",
    "- **Example Data**: Processed datasets in `../example_data/`\n",
    "- **Train/Test Splits**: Donor-based splits in `../train_test_splits/`\n",
    "- **Paper Reference**: [Hist2Cell: Deciphering Fine-grained Cellular Architectures from Histology Images](https://www.biorxiv.org/content/10.1101/2024.02.17.580852v1.full.pdf)\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Demo Limitations**: This demo used only 5 epochs for quick demonstration (~30 minutes on RTX 3090)\n",
    "- **Production Training**: For actual research, train for 20-50 epochs depending on convergence (several hours)\n",
    "- **GPU Requirements**: Training requires significant GPU memory (‚â•8GB recommended, 24GB+ ideal)\n",
    "- **Performance Monitoring**: Monitor both training and test metrics to avoid overfitting\n",
    "- **Data Split Strategy**: The donor-based split ensures realistic evaluation of model generalization capability\n",
    "\n",
    "### Citation\n",
    "\n",
    "If you use this code in your research, please cite:\n",
    "```bibtex\n",
    "@article{zhao2024hist2cell,\n",
    "  title={Hist2Cell: Deciphering Fine-grained Cellular Architectures from Histology Images},\n",
    "  author={Zhao, Weiqin and Liang, Zhuo and Huang, Xianjie and Huang, Yuanhua and Yu, Lequan},\n",
    "  journal={bioRxiv},\n",
    "  pages={2024--02},\n",
    "  year={2024},\n",
    "  publisher={Cold Spring Harbor Laboratory}\n",
    "}\n",
    "```\n",
    "\n",
    "Happy training and analyzing! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hist2Cell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
